# √âtape 4 : MLflow Tracking et Model Registry üéØ

## Vue d'ensemble

Cette √©tape impl√©mente le tracking complet des exp√©riences avec MLflow, incluant le logging des m√©triques, param√®tres, artifacts et mod√®les. MLflow utilise PostgreSQL pour le backend de m√©tadonn√©es et Minio/S3 pour le stockage des artifacts.

## Architecture

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                Training Script                        ‚îÇ
‚îÇ            (train_with_mlflow.py)                    ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                    ‚îÇ
                    ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ            MLflow Tracker Wrapper                     ‚îÇ
‚îÇ         (src/tracking/mlflow_tracker.py)             ‚îÇ
‚îÇ  - Log params, metrics, artifacts                    ‚îÇ
‚îÇ  - Start/end runs                                    ‚îÇ
‚îÇ  - Model logging                                     ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
      ‚îÇ                                        ‚îÇ
      ‚ñº                                        ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê                  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  MLflow Server  ‚îÇ                  ‚îÇ   Minio (S3)     ‚îÇ
‚îÇ   (Port 5001)   ‚îÇ                  ‚îÇ   (Port 9000)    ‚îÇ
‚îÇ                 ‚îÇ                  ‚îÇ                  ‚îÇ
‚îÇ  - Tracking UI  ‚îÇ‚óÑ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§  - Artifacts     ‚îÇ
‚îÇ  - REST API     ‚îÇ                  ‚îÇ  - Models        ‚îÇ
‚îÇ  - Experiments  ‚îÇ                  ‚îÇ  - Plots         ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò                  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
         ‚îÇ
         ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ   PostgreSQL    ‚îÇ
‚îÇ   (Port 5432)   ‚îÇ
‚îÇ                 ‚îÇ
‚îÇ  - Runs         ‚îÇ
‚îÇ  - Parameters   ‚îÇ
‚îÇ  - Metrics      ‚îÇ
‚îÇ  - Tags         ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

## Infrastructure Docker

### Services D√©ploy√©s

1. **PostgreSQL** (Backend de m√©tadonn√©es)
   - Port: 5432
   - Database: mlflow
   - User: mlflow / mlflow
   - Stocke: runs, params, metrics, tags

2. **Minio** (Stockage d'artifacts)
   - API Port: 9000
   - Console Port: 9001
   - Buckets: models, plants-images, data, **mlflow**
   - Stocke: models, plots, artifacts

3. **MLflow Server** (Tracking Server)
   - Port: 5001
   - UI: http://localhost:5001
   - Backend: PostgreSQL
   - Artifact Store: S3 (Minio)

### Configuration

#### docker-compose.yml

```yaml
services:
  # PostgreSQL for MLflow backend
  postgres:
    image: postgres:15-alpine
    ports: ["5432:5432"]
    environment:
      POSTGRES_USER: mlflow
      POSTGRES_PASSWORD: mlflow
      POSTGRES_DB: mlflow

  # Minio for S3-compatible storage  
  minio:
    image: minio/minio:latest
    ports: ["9000:9000", "9001:9001"]
    command: server /data --console-address ":9001"

  # MLflow tracking server
  mlflow:
    image: python:3.9-slim
    ports: ["5001:5000"]
    environment:
      MLFLOW_S3_ENDPOINT_URL: http://minio:9000
      AWS_ACCESS_KEY_ID: minioadmin
      AWS_SECRET_ACCESS_KEY: minioadmin
    command: |
      mlflow server 
        --backend-store-uri postgresql://mlflow:mlflow@postgres:5432/mlflow 
        --default-artifact-root s3://mlflow/ 
        --host 0.0.0.0 
        --port 5000
```

## Code Impl√©ment√©

### 1. MLflowTracker (`src/tracking/mlflow_tracker.py`)

Classe wrapper compl√®te pour MLflow avec les m√©thodes suivantes :

#### Initialisation
```python
tracker = MLflowTracker(
    tracking_uri="http://localhost:5001",
    experiment_name="plant_classification",
    s3_endpoint="http://localhost:9000",
    aws_access_key="minioadmin",
    aws_secret_key="minioadmin"
)
```

#### Gestion des Runs
```python
# D√©marrer un run
tracker.start_run(run_name="resnet18_experiment", tags={"model": "resnet18"})

# Terminer un run
tracker.end_run(status="FINISHED")
```

#### Logging de Param√®tres
```python
# Param√®tres uniques
tracker.log_param("learning_rate", 0.001)

# Param√®tres multiples
tracker.log_params({
    "backbone": "resnet18",
    "epochs": 10,
    "batch_size": 32
})
```

#### Logging de M√©triques
```python
# M√©trique unique
tracker.log_metric("accuracy", 0.95, step=10)

# M√©triques multiples par √©poque
tracker.log_metrics({
    "train_loss": 0.1,
    "val_loss": 0.2,
    "train_acc": 0.95,
    "val_acc": 0.93
}, step=epoch)

# M√©thode sp√©cialis√©e pour entra√Ænement
tracker.log_training_metrics(
    epoch=10,
    train_loss=0.1,
    train_acc=0.95,
    val_loss=0.2,
    val_acc=0.93,
    learning_rate=0.0001
)
```

#### Logging d'Artifacts
```python
# Fichier unique
tracker.log_artifact(Path("model.pth"), artifact_path="models")

# R√©pertoire entier
tracker.log_artifacts(Path("logs/"), artifact_path="training_logs")

# Figure matplotlib
tracker.log_figure(fig, "confusion_matrix.png")

# Dictionnaire JSON
tracker.log_dict(history, "training_history.json")

# Texte
tracker.log_text(summary, "model_summary.txt")
```

#### Logging de Mod√®les PyTorch
```python
# Log avec PyTorch flavor
tracker.log_model(
    model=model,
    artifact_path="model",
    registered_model_name="plant_classifier_resnet18"
)
```

#### Tags et M√©tadonn√©es
```python
# Tags uniques
tracker.set_tag("status", "production")

# Tags multiples
tracker.set_tags({
    "best_val_accuracy": "0.9500",
    "best_epoch": "7",
    "framework": "pytorch"
})

# M√©triques syst√®me automatiques
tracker.log_system_metrics()  # CPU, RAM, Python version, etc.
```

#### Recherche et Analyse
```python
# Rechercher des runs
runs = tracker.search_runs(
    filter_string="metrics.val_accuracy > 0.90",
    max_results=10,
    order_by=["metrics.val_accuracy DESC"]
)

# Obtenir le meilleur run
best_run = tracker.get_best_run(
    metric="val_accuracy",
    ascending=False  # Plus haut est mieux
)
```

### 2. Script d'Entra√Ænement avec MLflow (`train_with_mlflow.py`)

Script complet d'entra√Ænement avec int√©gration MLflow :

```bash
python3 train_with_mlflow.py \
    --backbone resnet18 \
    --epochs 10 \
    --batch-size 32 \
    --learning-rate 0.001 \
    --experiment-name plant_classification \
    --run-name resnet18_exp1
```

#### Param√®tres CLI

```
Model:
  --backbone           : resnet18, resnet50, efficientnet_b0, mobilenet_v2
  --epochs             : Nombre d'√©poques
  --batch-size         : Taille du batch
  --learning-rate      : Taux d'apprentissage
  --device             : cuda ou cpu

Training:
  --freeze-backbone    : Geler le backbone initialement
  --unfreeze-epoch     : √âpoque pour d√©geler
  --early-stopping-patience : Patience pour early stopping

MLflow:
  --experiment-name    : Nom de l'exp√©rience MLflow
  --run-name           : Nom du run (auto si non sp√©cifi√©)
  --no-mlflow          : D√©sactiver MLflow
```

#### Fonctionnalit√©s

- ‚úÖ Logging automatique de tous les hyperparam√®tres
- ‚úÖ Logging des m√©triques √† chaque √©poque (train/val loss/acc)
- ‚úÖ Logging du learning rate √† chaque √©poque
- ‚úÖ Logging de l'historique d'entra√Ænement (JSON)
- ‚úÖ Logging du mod√®le PyTorch (best model)
- ‚úÖ Logging des m√©triques syst√®me (CPU, RAM, Python)
- ‚úÖ Enregistrement dans le Model Registry
- ‚úÖ Tags pour cat√©gorisation

### 3. Script de V√©rification (`verify_mlflow.py`)

Script de test complet de l'installation MLflow :

```bash
python3 verify_mlflow.py
```

#### Tests Effectu√©s

1. ‚úÖ Connexion au serveur MLflow
2. ‚úÖ Cr√©ation d'exp√©rience
3. ‚úÖ D√©marrage de run
4. ‚úÖ Logging de param√®tres
5. ‚úÖ Logging de m√©triques
6. ‚úÖ Logging d'artifacts
7. ‚úÖ Setting de tags
8. ‚úÖ R√©cup√©ration d'informations de run

## Utilisation

### D√©marrer l'Infrastructure

```bash
# D√©marrer tous les services
docker-compose up -d

# V√©rifier l'√©tat
docker-compose ps

# Voir les logs
docker-compose logs -f mlflow
```

### V√©rifier MLflow

```bash
python3 verify_mlflow.py
```

Output attendu :
```
‚úì MLflow server is ready!
‚úì MLflow tracker initialized
‚úì Test run started
‚úì Parameters logged
‚úì Metrics logged (5 steps)
‚úì Artifact logged
‚úì Tags set
‚úì ALL MLFLOW TESTS PASSED
```

### Entra√Æner avec MLflow

```bash
# Entra√Ænement rapide (3 √©poques de test)
python3 train_with_mlflow.py --epochs 3

# Entra√Ænement complet
python3 train_with_mlflow.py --epochs 10 --backbone resnet18

# Entra√Ænement avec mod√®le diff√©rent
python3 train_with_mlflow.py --epochs 15 --backbone resnet50 \
    --batch-size 16 --learning-rate 0.0001

# Sans MLflow
python3 train_with_mlflow.py --epochs 10 --no-mlflow
```

### Acc√©der √† l'Interface MLflow

1. **Ouvrir le navigateur** : http://localhost:5001

2. **Vue des Exp√©riences** :
   - Liste de toutes les exp√©riences
   - Nombre de runs par exp√©rience
   - Liens vers les d√©tails

3. **Vue des Runs** :
   - Tableau comparatif de tous les runs
   - M√©triques en colonnes (triables, filtrables)
   - Graphiques de comparaison

4. **D√©tails d'un Run** :
   - Onglet **Overview** : Informations g√©n√©rales
   - Onglet **Parameters** : Tous les hyperparam√®tres
   - Onglet **Metrics** : Graphiques des m√©triques
   - Onglet **Artifacts** : Fichiers (mod√®les, plots, logs)
   - Onglet **Tags** : M√©tadonn√©es

### Acc√©der aux Artifacts (Minio)

1. **Ouvrir le navigateur** : http://localhost:9001

2. **Se connecter** :
   - Username: minioadmin
   - Password: minioadmin

3. **Naviguer** :
   - Bucket `mlflow` : Tous les artifacts MLflow
   - Structure : `experiment_name/run_id/artifacts/`

## M√©triques Track√©es

### Par √âpoque

- `train_loss` : Loss sur le training set
- `train_accuracy` : Accuracy sur le training set
- `val_loss` : Loss sur le validation set
- `val_accuracy` : Accuracy sur le validation set
- `learning_rate` : Learning rate courant

### Syst√®me

- `python_version` : Version Python
- `platform` : OS et architecture
- `cpu_count` : Nombre de CPUs
- `memory_gb` : RAM totale en GB

### Param√®tres Logg√©s

```python
{
    "backbone": "resnet18",
    "epochs": 10,
    "batch_size": 32,
    "learning_rate": 0.001,
    "device": "cpu",
    "freeze_backbone": True,
    "unfreeze_epoch": 5,
    "early_stopping_patience": 10,
    "optimizer": "AdamW",
    "scheduler": "CosineAnnealingLR",
    "loss_function": "CrossEntropyLoss",
    "num_classes": 2,
    "train_size": 280,
    "val_size": 60,
    "test_size": 60,
    "total_parameters": 11689538,
    "trainable_parameters": 1443842
}
```

### Artifacts Logg√©s

- `training/training_history.json` : Historique complet
- `models/best_model.pth` : Meilleur checkpoint
- `model/` : Mod√®le PyTorch avec MLflow flavor

## Comparaison des Runs

### Via l'UI MLflow

1. S√©lectionner plusieurs runs (checkbox)
2. Cliquer "Compare"
3. Voir les tableaux et graphiques comparatifs
4. Exporter en CSV si besoin

### Via l'API Python

```python
from src.tracking.mlflow_tracker import MLflowTracker

tracker = MLflowTracker(tracking_uri="http://localhost:5001")

# Rechercher les meilleurs runs
best_runs = tracker.search_runs(
    filter_string="metrics.val_accuracy > 0.90",
    max_results=5,
    order_by=["metrics.val_accuracy DESC"]
)

for run in best_runs:
    print(f"Run: {run['tags.mlflow.runName']}")
    print(f"Accuracy: {run['metrics.val_accuracy']:.4f}")
    print(f"Backbone: {run['params.backbone']}")
    print()
```

## Model Registry

### Enregistrement Automatique

Lors de l'entra√Ænement avec `train_with_mlflow.py`, le mod√®le est automatiquement enregistr√© :

```python
mlflow.pytorch.log_model(
    model=model,
    artifact_path="model",
    registered_model_name=f"{backbone}_plant_classifier"
)
```

### Versions de Mod√®les

- MLflow cr√©e automatiquement des versions (v1, v2, v3...)
- Chaque version est li√©e √† un run sp√©cifique
- Possibilit√© de promouvoir en "Production", "Staging", etc.

### Charger un Mod√®le depuis le Registry

```python
import mlflow.pytorch

# Charger la version de production
model_uri = "models:/resnet18_plant_classifier/Production"
model = mlflow.pytorch.load_model(model_uri)

# Ou une version sp√©cifique
model_uri = "models:/resnet18_plant_classifier/1"
model = mlflow.pytorch.load_model(model_uri)
```

## Configuration

### Variables d'Environnement (`.env`)

```bash
# MLflow Configuration
MLFLOW_TRACKING_URI=http://localhost:5001
MLFLOW_EXPERIMENT_NAME=plant_classification
MLFLOW_S3_ENDPOINT_URL=http://localhost:9000
AWS_ACCESS_KEY_ID=minioadmin
AWS_SECRET_ACCESS_KEY=minioadmin
```

### Configuration Programmatique

```python
import os
os.environ["MLFLOW_TRACKING_URI"] = "http://localhost:5001"
os.environ["MLFLOW_S3_ENDPOINT_URL"] = "http://localhost:9000"
os.environ["AWS_ACCESS_KEY_ID"] = "minioadmin"
os.environ["AWS_SECRET_ACCESS_KEY"] = "minioadmin"
```

## Commandes Utiles

### Docker

```bash
# D√©marrer
docker-compose up -d

# Arr√™ter
docker-compose down

# Red√©marrer MLflow
docker-compose restart mlflow

# Logs
docker-compose logs -f mlflow
docker-compose logs -f postgres
docker-compose logs -f minio

# √âtat
docker-compose ps
```

### MLflow CLI

```bash
# Lister les exp√©riences
mlflow experiments list --tracking-uri http://localhost:5001

# Chercher des runs
mlflow runs list --experiment-name plant_classification

# Servir un mod√®le
mlflow models serve -m models:/resnet18_plant_classifier/1 -p 8080
```

## Troubleshooting

### MLflow ne d√©marre pas

```bash
# V√©rifier les logs
docker-compose logs mlflow

# Red√©marrer
docker-compose restart mlflow

# Recr√©er le container
docker-compose up -d --force-recreate mlflow
```

### Erreur de connexion PostgreSQL

```bash
# V√©rifier que PostgreSQL est pr√™t
docker-compose logs postgres

# Attendre le healthcheck
docker-compose ps postgres
```

### Artifacts non accessibles

```bash
# V√©rifier Minio
docker-compose logs minio

# V√©rifier le bucket mlflow
# Aller sur http://localhost:9001
```

### Port 5001 d√©j√† utilis√©

Modifier dans `docker-compose.yml` et `.env` :
```yaml
ports:
  - "5002:5000"  # Au lieu de 5001:5000
```

```bash
MLFLOW_TRACKING_URI=http://localhost:5002
```

## Avantages de MLflow

### ‚úÖ Tra√ßabilit√© Compl√®te
- Historique de tous les runs
- Comparaison facile
- Reproductibilit√© garantie

### ‚úÖ Collaboration
- Partage d'exp√©riences
- UI centralis√©e
- Artifacts accessibles

### ‚úÖ Versioning de Mod√®les
- Registry centralis√©
- Promotion de versions
- Rollback facile

### ‚úÖ Int√©gration
- Compatible avec PyTorch, TensorFlow, sklearn...
- API REST pour CI/CD
- Export vers production

## Prochaines √âtapes (√âtape 5)

L'infrastructure MLflow est maintenant en place pour :
- **API REST** : Servir les mod√®les enregistr√©s
- **WebApp** : Interface de pr√©diction
- **CI/CD** : D√©ploiement automatique des mod√®les track√©s
- **Monitoring** : Suivi des performances en production

## R√©sum√©

**√âtape 4 : COMPL√âT√âE AVEC SUCC√àS !** ‚úÖ

- ‚úÖ Infrastructure Docker (PostgreSQL + MLflow + Minio)
- ‚úÖ MLflowTracker wrapper complet
- ‚úÖ Script d'entra√Ænement avec tracking int√©gr√©
- ‚úÖ Script de v√©rification
- ‚úÖ Interface UI accessible
- ‚úÖ Model Registry fonctionnel
- ‚úÖ Documentation compl√®te

**Pr√™t pour l'√âtape 5** : API REST pour serving de mod√®les

---

**Date** : 28 octobre 2025
**Lignes de code** : ~800 lignes
**Services d√©ploy√©s** : 4 (Postgres, Minio, MLflow, Minio-client)
**Ports utilis√©s** : 5001 (MLflow), 5432 (Postgres), 9000 (Minio API), 9001 (Minio Console)
