# üöÄ Guide de D√©marrage Rapide - Pr√©sentation MLOps

Ce guide vous permet de lancer rapidement le projet pour votre pr√©sentation de 10 minutes.

## ‚ö° D√©marrage en 3 commandes

```bash
# 1. Construire les images Docker
docker compose build

# 2. Initialiser Airflow (une seule fois)
docker compose up airflow-init

# 3. Lancer tous les services
docker compose up -d
```

## üìã V√©rification des Services

Attendez environ 30-60 secondes que tous les services d√©marrent, puis v√©rifiez :

```bash
# Voir l'√©tat des conteneurs
docker compose ps

# V√©rifier les logs si n√©cessaire
docker compose logs -f airflow-scheduler
docker compose logs -f api
```

## üåê URLs d'Acc√®s

| Service | URL | Credentials |
|---------|-----|-------------|
| **Airflow UI** | http://localhost:8080 | admin / admin |
| **MLflow** | http://localhost:5500 | - |
| **MinIO Console** | http://localhost:9001 | minioadmin / minioadmin |
| **FastAPI Docs** | http://localhost:8000/docs | - |
| **Streamlit** | http://localhost:8501 | - |
| **Grafana** | http://localhost:3000 | admin / admin |
| **Prometheus** | http://localhost:9090 | - |

## üéØ Sc√©nario de D√©monstration

### √âtape 1 : Montrer l'architecture (2 min)
- Ouvrir le README.md et montrer les diagrammes Mermaid
- Expliquer le flux : Data ‚Üí Training ‚Üí Serving ‚Üí Monitoring

### √âtape 2 : Lancer le pipeline de training (3 min)
```bash
# Ouvrir Airflow UI : http://localhost:8080
# Login: admin / admin
# 1. Cliquer sur le DAG "dandelion_data_pipeline"
# 2. Cliquer sur le bouton "Play" (‚ñ∂Ô∏è) en haut √† droite
# 3. Cliquer sur "Trigger DAG"
```

**Pendant que le pipeline tourne, montrer :**
- MinIO : http://localhost:9001 ‚Üí Voir les buckets (dandelion-data, dandelion-models, mlflow-artifacts)
- MLflow : http://localhost:5500 ‚Üí Voir l'exp√©rience "dandelion-classifier" (peut √™tre vide au d√©but)

### √âtape 3 : Monitoring du Training (2 min)
```bash
# Dans Airflow, cliquer sur le DAG run en cours
# Montrer la progression des t√¢ches :
# ‚úÖ create_folders ‚Üí download_images ‚Üí upload_raw ‚Üí preprocess ‚Üí upload_processed ‚Üí train_model
```

**Pendant l'entra√Ænement :**
- MLflow commence √† logger les m√©triques en temps r√©el
- Rafra√Æchir MLflow pour voir le run appara√Ætre

### √âtape 4 : Test de l'API de Pr√©diction (2 min)

Une fois le training termin√© (~5-7 min), tester l'API :

```bash
# Option 1 : Via l'interface Streamlit
# Ouvrir : http://localhost:8501
# 1. Uploader une image de pissenlit ou d'herbe
# 2. Cliquer sur "Pr√©dire via l'API"
# 3. Voir le r√©sultat : classe + confiance

# Option 2 : Via la doc FastAPI
# Ouvrir : http://localhost:8000/docs
# 1. Tester GET /health ‚Üí Voir que le mod√®le est "ready"
# 2. Tester POST /predict ‚Üí Uploader une image
```

### √âtape 5 : Monitoring avec Grafana (1 min)
```bash
# Ouvrir Grafana : http://localhost:3000
# Login: admin / admin
# 1. Aller dans "Dashboards"
# 2. Ouvrir "Dandelion Classifier" ‚Üí M√©triques API (pr√©dictions, latence)
# 3. Ouvrir "Airflow Overview" ‚Üí M√©triques du scheduler
```

## üî• Astuces pour la Pr√©sentation

### Si le training prend trop de temps
Le training complet prend ~5-7 minutes. Pour votre pr√©sentation :

**Option A : Lancer le pipeline AVANT la pr√©sentation**
```bash
# 30 minutes avant votre pr√©sentation
docker compose up -d
# Attendre que Airflow d√©marre (~2 min)
# Trigger le DAG manuellement
# Pendant le training, pr√©parer vos slides
```

**Option B : Utiliser un mod√®le pr√©-entra√Æn√©**
Si vous avez d√©j√† un mod√®le de votre d√©mo pr√©c√©dente :
```bash
# Les volumes Docker persistent les donn√©es
# Si vous avez d√©j√† run le pipeline une fois, le mod√®le est stock√©
# L'API le chargera automatiquement au d√©marrage
```

### Si Airflow ne d√©marre pas
```bash
# R√©initialiser compl√®tement Airflow
docker compose down -v  # ‚ö†Ô∏è Efface tout !
docker compose up airflow-init
docker compose up -d
```

### T√©l√©charger une image de test
```bash
# T√©l√©charger une image de pissenlit pour la d√©mo
curl -o test_dandelion.jpg "https://raw.githubusercontent.com/btphan95/greenr-airflow/refs/heads/master/data/dandelion/00000001.jpg"

# T√©l√©charger une image d'herbe
curl -o test_grass.jpg "https://raw.githubusercontent.com/btphan95/greenr-airflow/refs/heads/master/data/grass/00000001.jpg"
```

## üêõ D√©pannage Rapide

### Airflow scheduler/webserver en erreur
```bash
# V√©rifier que l'init s'est bien pass√©
docker compose logs airflow-init | tail -20

# Si vous voyez "ERROR: You need to initialize the database"
docker compose stop airflow-scheduler airflow-webserver
docker compose up airflow-init
docker compose up -d airflow-scheduler airflow-webserver
```

### L'API dit "Model not available"
C'est normal au d√©marrage ! Le mod√®le n'existe pas encore.
- Lancez le pipeline dans Airflow
- Attendez que la t√¢che `train_model` soit ‚úÖ
- Red√©marrez l'API : `docker compose restart api`

### MinIO : Buckets vides
```bash
# V√©rifier que bootstrap s'est ex√©cut√©
docker compose logs bootstrap

# Si n√©cessaire, le relancer
docker compose up bootstrap
```

## üìä R√©sultats Attendus

Apr√®s l'ex√©cution compl√®te du pipeline :

- **Donn√©es** : 400 images dans MinIO (200 pissenlits + 200 herbe)
- **Mod√®le** : `best_model.pt` dans MinIO bucket `dandelion-models`
- **MLflow** : 1 run avec m√©triques (accuracy ~0.85-0.90, loss, f1-score)
- **API** : Status "ready" avec 2 classes [dandelion, grass]
- **Temps total** : ~5-7 minutes sur CPU

## üõë Arr√™ter Tout

```bash
# Arr√™ter tous les services (garde les donn√©es)
docker compose stop

# Arr√™ter et supprimer tout (‚ö†Ô∏è efface les donn√©es)
docker compose down -v
```

## üìû Aide Pendant la Pr√©sentation

Si quelque chose ne fonctionne pas pendant votre d√©mo :

1. **Montrez les diagrammes** dans le README (toujours fonctionnel !)
2. **Expliquez l'architecture** avec les screenshots existants dans `docs/screenshots/`
3. **Montrez le code** : pipelines Airflow, mod√®le PyTorch, API FastAPI
4. **Backup plan** : Avoir des screenshots/vid√©os de chaque √©tape

---

‚ú® **Bon courage pour votre pr√©sentation !** ‚ú®
