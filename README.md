# MLOps Dandelion Classifier

Projet MLOps minimaliste pour classifier des images de pissenlits et d'herbe.
Enzo BERREUR, Elea NIZAM, Jean-Baptiste BRUN, Elisa LECLERC

## Stack

- **Orchestration** : Apache Airflow 2
- **Mod√©lisation** : PyTorch + torchvision
- **MLOps** : MLflow (tracking), MinIO (artifacts & datasets)
- **Serving** : FastAPI + Streamlit
- **Conteneurisation** : Docker, Docker Compose, Kubernetes (Minikube)
- **CI/CD** : GitHub Actions
- **Monitoring** : Prometheus + Grafana (optionnel)

## Choix techniques & objectifs

- **Airflow + MinIO** : pipeline d√©claratif pour automatiser le t√©l√©chargement des images, la pr√©paration et l'entra√Ænement. MinIO offre un stockage S3 compatible reproductible en local et en cluster.
- **PyTorch** : mod√®le l√©ger (ResNet18) finement ajust√© pour un dataset restreint (200 images par classe) avec des transformations simples (resize + augmentation l√©g√®re) afin de limiter l'overfitting.
- **MLflow Tracking** : centralise les m√©triques (loss, accuracy, f1) et l'enregistrement du mod√®le. Chaque run conserve le code source et permet la comparaison de plusieurs entra√Ænements.
- **FastAPI** : service de pr√©diction synchrone qui t√©l√©charge le dernier checkpoint depuis MinIO au d√©marrage, expose `/predict` et `/health`, et publie des m√©triques Prometheus.
- **Streamlit** : interface pour tester rapidement les pr√©dictions et monitorer la disponibilit√© de l'API (mode local ou API distante).
- **Prometheus + Grafana** : supervision des appels API (`/predict`) et de la sant√© du scheduler Airflow via `statsd-exporter`. Deux dashboards sont provisionn√©s automatiquement.
- **CI/CD GitHub Actions** : pipeline unique (tests ‚Üí build ‚Üí d√©ploiement Minikube) pour valider la stack bout-en-bout. Les images sont publi√©es sur GHCR et peuvent √™tre retag√©es pour Docker Hub.

### R√©sultats observ√©s (r√©f√©rence)

Les m√©triques d√©pendent fortement des tirages al√©atoires (split train/val). Avec la configuration par d√©faut (`IMAGE_SIZE=224`, `EPOCHS=5`), un run typique donne :

- **Accuracy validation** : 0.90 ¬± 0.03
- **F1-score validation** : 0.89 ¬± 0.04
- **Temps d'entra√Ænement** : ~4 minutes sur CPU (LocalExecutor Airflow)

### Captures d'√©cran principales

| Vue | Description |
| --- | ----------- |
| ![Run MLflow](docs/screenshots/mlflow.png) | Vue d'ensemble de l'exp√©rience `dandelion-classifier`, incluant les param√®tres et le succ√®s du run. |
| ![Courbes MLflow](docs/screenshots/mlflow_metrics.png) | Historique des m√©triques (loss & accuracy) captur√©es pendant l'entra√Ænement PyTorch. |
| ![Stockage MinIO](docs/screenshots/minio.png) | Buckets `dandelion-models` et `mlflow-artifacts` contenant les jeux de donn√©es et le checkpoint `models/latest/best_model.pt`. |
| ![API Streamlit](docs/screenshots/streamlit.png) | Interface utilisateur pour tester les pr√©dictions depuis un navigateur. |
| ![Dashboard API Grafana](docs/screenshots/grafana_calssifier.png) | Monitoring temps r√©el du trafic `/predict` (latence p90 et nombre d'appels). |
| ![Dashboard Airflow Grafana](docs/screenshots/airflow_data_pipeline.png) | Supervision du scheduler Airflow et du throughput des t√¢ches via StatsD exporter. |

> Captures r√©alis√©es sur l‚Äôenvironnement Docker Compose (identique √† l‚Äôenvironnement Minikube c√¥t√© services).

## Images Docker

- **GHCR (par d√©faut CI/CD)** : `https://ghcr.io/enzoberreur/mlops/mlops-app:<commit-sha>`
- **Publication Docker Hub (option)** :
  ```bash
  export DOCKERHUB_USER=enzoberreur
  docker pull ghcr.io/enzoberreur/mlops/mlops-app:<commit-sha>
  docker tag ghcr.io/enzoberreur/mlops/mlops-app:<commit-sha> docker.io/$DOCKERHUB_USER/mlops-app:<commit-sha>
  docker push docker.io/$DOCKERHUB_USER/mlops-app:<commit-sha>
  ```
  Cr√©ez le repository Docker Hub `docker.io/enzoberreur/mlops-app` puis communiquez les URLs des tags pertinents (ex. `https://hub.docker.com/r/enzoberreur/mlops-app/tags?name=<commit-sha>`).

## Art√©facts de production

- **Buckets MinIO** :
  - Donn√©es brutes : `dandelion-data/raw/`
  - Donn√©es pr√©trait√©es : `dandelion-data/processed/`
  - Mod√®le : `dandelion-models/models/latest/best_model.pt`
  - Artifacts MLflow : `mlflow-artifacts/<experiment-id>/<run-id>/artifacts/`
- **MLflow Experiment** : `dandelion-classifier`
  - Les runs sont tagg√©s avec l'ID Airflow (`dag_id`, `execution_date`) pour tracer leur provenance.
  - Reproductibilit√© garantie par la sauvegarde du mod√®le `mlflow.pytorch`.
- **Airflow Vars/Connections** : g√©r√©es via `.env` et inject√©es dans les containers (`MINIO_*`, `MLFLOW_TRACKING_URI`, etc.). Export possible via `airflow variables export`.

## Architecture

### Pipeline MLOps Complet

```mermaid
graph LR
    subgraph "1Ô∏è‚É£ DATA INGESTION"
        A[GitHub Images] -->|t√©l√©charge| B[Airflow DAG]
        B -->|stocke| C[MinIO S3]
    end
    
    subgraph "2Ô∏è‚É£ TRAINING"
        C -->|charge donn√©es| D[PyTorch ResNet18]
        D -->|log m√©triques| E[MLflow :5500]
        D -->|sauvegarde mod√®le| C
    end
    
    subgraph "3Ô∏è‚É£ SERVING"
        C -->|charge mod√®le| F[FastAPI :8000]
        F -->|UI web| G[Streamlit :8501]
    end
    
    subgraph "4Ô∏è‚É£ MONITORING"
        F -->|m√©triques| H[Prometheus :9090]
        H -->|dashboards| I[Grafana :3000]
    end

    style A fill:#e3f2fd
    style C fill:#e1f5ff
    style D fill:#fff3e0
    style E fill:#fff3e0
    style F fill:#f3e5f5
    style G fill:#f3e5f5
    style H fill:#e8f5e9
    style I fill:#e8f5e9
```

**Explication du flux :**

1. **Data Ingestion** : Airflow t√©l√©charge automatiquement 400 images (200 pissenlits + 200 herbe) depuis GitHub et les stocke dans MinIO
2. **Training** : PyTorch charge les donn√©es depuis MinIO, entra√Æne un mod√®le ResNet18, et log toutes les m√©triques dans MLflow. Le mod√®le entra√Æn√© est sauvegard√© dans MinIO
3. **Serving** : L'API FastAPI charge le meilleur mod√®le depuis MinIO au d√©marrage. Streamlit fournit une interface web pour uploader des images et obtenir des pr√©dictions
4. **Monitoring** : FastAPI expose des m√©triques Prometheus (nombre de pr√©dictions, latence). Grafana visualise ces m√©triques en temps r√©el via des dashboards

### Composants Principaux

| Service | Port | R√¥le |
|---------|------|------|
| **Airflow** | 8080 | Orchestration des pipelines (data + training) |
| **MinIO** | 9000/9001 | Stockage S3 (donn√©es + mod√®les + artifacts) |
| **MLflow** | 5500 | Tracking des exp√©riences ML |
| **FastAPI** | 8000 | API de pr√©diction |
| **Streamlit** | 8501 | Interface utilisateur web |
| **Prometheus** | 9090 | Collecte des m√©triques |
| **Grafana** | 3000 | Visualisation des dashboards |

### Flux de Donn√©es D√©taill√©

```mermaid
sequenceDiagram
    participant U as Utilisateur
    participant S as Streamlit
    participant A as FastAPI
    participant M as MinIO
    participant ML as MLflow
    participant Air as Airflow
    
    Note over Air,M: Pipeline d'entra√Ænement
    Air->>M: 1. Upload donn√©es brutes
    Air->>Air: 2. Pr√©traitement images
    Air->>M: 3. Upload donn√©es trait√©es
    Air->>ML: 4. Training PyTorch
    ML->>M: 5. Sauvegarde mod√®le
    
    Note over U,A: Inf√©rence
    U->>S: Upload image
    S->>A: POST /predict
    A->>M: Charge mod√®le (si n√©cessaire)
    A->>A: Pr√©diction
    A->>S: R√©sultat + confiance
    S->>U: Affiche r√©sultat
```

**D√©roulement chronologique d√©taill√© :**

**Phase 1 - Pipeline d'entra√Ænement (ex√©cut√© par Airflow) :**
1. Airflow d√©marre le DAG `dandelion_data_pipeline` (programm√© hebdomadairement ou d√©clench√© manuellement)
2. T√©l√©chargement de 200 images de pissenlits et 200 images d'herbe depuis GitHub
3. Upload des images brutes dans MinIO (bucket `dandelion-data/raw/`)
4. Pr√©traitement : redimensionnement √† 128√ó128 pixels et normalisation
5. Upload des images trait√©es dans MinIO (bucket `dandelion-data/processed/`)
6. Lancement de l'en√©cution PyTorch : entra√Ænement du mod√®le ResNet18 sur 3-5 √©poques
7. MLflow enregistre automatiquement : accuracy, loss, F1-score, hyperparam√®tres
8. Sauvegarde du meilleur mod√®le dans MinIO (bucket `dandelion-models/models/latest/best_model.pt`)

**Phase 2 - Inf√©rence en temps r√©el (utilisateur final) :**
1. L'utilisateur ouvre l'interface Streamlit sur son navigateur (http://localhost:8501)
2. L'utilisateur uploade une photo de plante via l'interface web
3. Streamlit envoie l'image √† l'API FastAPI via une requ√™te POST sur `/predict`
4. FastAPI charge le mod√®le depuis MinIO (uniquement au premier d√©marrage, puis gard√© en m√©moire)
5. Le mod√®le effectue la pr√©diction : classe (dandelion/grass) + score de confiance
6. FastAPI retourne le r√©sultat JSON avec la pr√©diction et les probabilit√©s pour chaque classe
7. Streamlit affiche visuellement le r√©sultat √† l'utilisateur avec la confiance
8. Parall√®lement, Prometheus collecte les m√©triques (temps de r√©ponse, nombre de pr√©dictions)
9. Grafana met √† jour les dashboards en temps r√©el pour le monitoring

## Pr√©requis

- Docker & Docker Compose
- Python 3.10+ (pour ex√©cuter les scripts en local)
- Minikube (pour l'environnement "prod")

## D√©marrage rapide local (Docker Compose)

### ‚ö° Lancement en 3 √©tapes

```bash
# 1. Construire les images Docker
docker compose build

# 2. Initialiser Airflow (une seule fois)
docker compose up airflow-init

# 3. Lancer tous les services
docker compose up -d
```

### üìã V√©rification

Attendez 30-60 secondes que tous les services d√©marrent :

```bash
# Voir l'√©tat des conteneurs
docker compose ps

# V√©rifier les logs
docker compose logs -f airflow-scheduler
docker compose logs -f api
```

### üåê URLs d'acc√®s

Services expos√©s :
- Airflow UI : http://localhost:8080 (login/password `admin/admin`)
- FastAPI : http://localhost:8000/docs
- Streamlit : http://localhost:8501
- MLflow : http://localhost:5500
- MinIO : http://localhost:9001 (console - `minioadmin/minioadmin`)
- Prometheus : http://localhost:9090
- Grafana : http://localhost:3000 (`admin/admin`)

### üéØ D√©mo Rapide (10 minutes)

**1. Lancer le pipeline d'entra√Ænement** (7 min d'ex√©cution)
- Ouvrir Airflow UI : http://localhost:8080 (`admin/admin`)
- Cliquer sur le DAG `dandelion_data_pipeline`
- Cliquer sur le bouton ‚ñ∂Ô∏è "Trigger DAG"
- Le pipeline va : t√©l√©charger 400 images ‚Üí pr√©traiter ‚Üí entra√Æner ResNet18 ‚Üí sauvegarder dans MinIO

**2. Pendant l'entra√Ænement, montrer :**
- **MinIO** (http://localhost:9001) : Voir les buckets et les donn√©es upload√©es
- **MLflow** (http://localhost:5500) : Voir les m√©triques en temps r√©el
- **Grafana** (http://localhost:3000) : Dashboards de monitoring

**3. Tester les pr√©dictions** (une fois le training termin√©)
- **Streamlit** (http://localhost:8501) : Uploader une image et voir la pr√©diction
- **FastAPI** (http://localhost:8000/docs) : Tester l'endpoint `/predict`

### üêõ D√©pannage

**Airflow ne d√©marre pas :**
```bash
docker compose down -v  # ‚ö†Ô∏è Efface tout
docker compose up airflow-init
docker compose up -d
```

**L'API dit "Model not available" :**
C'est normal au d√©marrage ! Le mod√®le n'existe pas encore. Lancez d'abord le pipeline Airflow.

**T√©l√©charger des images de test :**
```bash
# Image de pissenlit
curl -o test_dandelion.jpg "https://raw.githubusercontent.com/btphan95/greenr-airflow/refs/heads/master/data/dandelion/00000001.jpg"

# Image d'herbe
curl -o test_grass.jpg "https://raw.githubusercontent.com/btphan95/greenr-airflow/refs/heads/master/data/grass/00000001.jpg"
```

**Arr√™ter les services :**
```bash
docker compose stop  # Garde les donn√©es
docker compose down -v  # ‚ö†Ô∏è Supprime tout
```

Sur Streamlit, vous pouvez choisir entre deux modes d'inf√©rence :
- **API distante** : envoie l'image √† FastAPI (`/predict`).
- **Local (MinIO)** : t√©l√©charge un checkpoint `.pt` depuis MinIO et ex√©cute l'inf√©rence directement dans l'application.

> Astuce : ex√©cuter une premi√®re fois `python scripts/bootstrap_minio.py` pour cr√©er les buckets sur MinIO (si vous n'utilisez pas Docker Compose).

### Pipelines Airflow

- `dandelion_data_pipeline` :
  1. T√©l√©charge les images des deux classes depuis GitHub.
  2. Stocke les donn√©es brutes et pr√©-trait√©es dans MinIO.
  3. Lance l'entra√Ænement du mod√®le, loggue dans MLflow et pousse le mod√®le sur MinIO.
- `dandelion_retrain_pipeline` : synchronise les derni√®res donn√©es pr√©trait√©es depuis MinIO puis relance l'entra√Ænement.

### Monitoring

Prometheus scrappe l'endpoint `/metrics` expos√© par FastAPI. Le dashboard Grafana (import√© automatiquement) montre :
- compteur total des pr√©dictions,
- latence p90 de l'endpoint `/predict`.

L'exporter StatsD collecte √©galement les m√©triques Airflow (scheduler heartbeat, DagRun success/fail) accessibles dans le dashboard "Airflow Overview".

## D√©veloppement local hors Docker

```bash
python -m venv .venv
source .venv/bin/activate
pip install -r requirements.txt
python scripts/bootstrap_minio.py
python models/train.py --data-dir data/processed  # supposant des donn√©es d√©j√† t√©l√©charg√©es
uvicorn app.api.main:app --reload
streamlit run app/webapp/streamlit_app.py
```

## Tests

```bash
pytest
```

## D√©ploiement Minikube

1. D√©marrer minikube :
   ```bash
   minikube start --driver=docker
   ```
2. Construire et charger l'image :
   ```bash
   docker build -t mlops-app:latest .
   minikube image load mlops-app:latest
   ```
3. D√©ployer :
   ```bash
   kubectl apply -f k8s/minikube-manifest.yaml
   ```
4. Consulter les services :
   ```bash
   kubectl get svc -n mlops
   minikube service --namespace mlops api
   minikube service --namespace mlops streamlit
   ```

## CI/CD GitHub Actions

- `tests` : installe les d√©pendances et ex√©cute `pytest`.
- `build` : construit l'image Docker et la pousse sur GHCR (`ghcr.io/<repo>/mlops-app`).
- `deploy` : d√©marre Minikube dans le runner, charge l'image publi√©e et applique les manifests Kubernetes.

| √âtape | Capture |
| --- | --- |
| Tests unitaires | ![GitHub Actions - tests](docs/screenshots/github_action_tests.png) |
| Build & push | ![GitHub Actions - build](docs/screenshots/github_action_build.png) |
| D√©ploiement Minikube | ![GitHub Actions - deploy](docs/screenshots/github_action_deploy.png) |

Cr√©er un environnement GitHub Actions s√©curis√© :
- Le d√©p√¥t doit √™tre public pour que GHCR soit accessible sans credentials suppl√©mentaires (sinon, fournir un `imagePullSecret`).
- Ajuster les URLs du manifeste K8s si vous utilisez un autre endpoint MinIO/MLflow.

## Structure du d√©p√¥t

```
mlops-project/
‚îú‚îÄ‚îÄ airflow/dags/...
‚îú‚îÄ‚îÄ app/api/main.py          # API FastAPI
‚îú‚îÄ‚îÄ app/webapp/streamlit_app.py
‚îú‚îÄ‚îÄ models/                  # Mod√®le PyTorch & utilitaires
‚îú‚îÄ‚îÄ monitoring/              # Prometheus & Grafana config
‚îú‚îÄ‚îÄ k8s/minikube-manifest.yaml
‚îú‚îÄ‚îÄ scripts/bootstrap_minio.py
‚îú‚îÄ‚îÄ tests/test_utils.py
‚îú‚îÄ‚îÄ docker-compose.yml
‚îú‚îÄ‚îÄ Dockerfile
‚îú‚îÄ‚îÄ requirements.txt
‚îî‚îÄ‚îÄ .github/workflows/ci_cd.yml
```

## Notes

- Dataset : 200 images par classe, r√©cup√©r√©es directement depuis GitHub.
- Les DAGs utilisent les variables Airflow (`data_base_path`, `image_size`, etc.) pour personnaliser les chemins.
- L'API t√©l√©charge automatiquement la derni√®re version du mod√®le depuis MinIO au d√©marrage.
- MLflow enregistre le mod√®le (`mlflow.pytorch.log_model`) et le meilleur checkpoint dans MinIO.
